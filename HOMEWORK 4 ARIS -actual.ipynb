{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, regexp_tokenize\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing page with BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from website and create a BeautifulSoup class to parse document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/39 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#create lists where store the data\n",
    "title=[]\n",
    "price=[]\n",
    "n_room=[]\n",
    "mq=[]\n",
    "n_bathroom=[]\n",
    "plan=[]\n",
    "desc=[]\n",
    "#iterate to take data from different page\n",
    "count=1\n",
    "for num in tqdm(range(1,40)):\n",
    "    url = str('www.immobiliare.it/vendita-case/roma/?criterio=rilevanza&pag='+str(num))\n",
    "    r = requests.get('https://' +url)\n",
    "    data = r.text\n",
    "    soup = BeautifulSoup(data,'html.parser')\n",
    "    \n",
    "    #iterate on the main class which contain the data that we want\n",
    "    for announcement in soup.find_all('div', class_='listing-item_body--content'):\n",
    "        #find all the features\n",
    "        total_features = announcement.find('ul', class_='listing-features list-piped')\n",
    "        if len(total_features)==7:\n",
    "            #announcement_title= announcement.find('p', class_='titolo text-primary').text.strip()\n",
    "            title.append('announcement_'+str(count))\n",
    "            feature = announcement.find_all('li')\n",
    "            feature_price = feature[0].text.strip()\n",
    "            if ('%' in feature_price)== True:\n",
    "                title.pop()\n",
    "            else:\n",
    "                price.append(feature_price[2:].replace('.',''))\n",
    "                feature_n_room = feature[1].text[0]\n",
    "                n_room.append(feature_n_room)\n",
    "                feature_mq = feature[2].text[0:-12]\n",
    "                mq.append(feature_mq)\n",
    "                feature_n_bathroom = feature[3].text[0:-5]\n",
    "                n_bathroom.append(feature_n_bathroom)\n",
    "                feature_plan = feature[4].text[0:-7].strip()\n",
    "                #check if there is a character inside plan data, if yes pop last element in the others lists to mantain dimension\n",
    "                if feature_plan.isalpha()==True:\n",
    "                    title.pop()\n",
    "                    price.pop()\n",
    "                    n_room.pop()\n",
    "                    mq.pop()\n",
    "                    n_bathroom.pop()\n",
    "                    count+=0\n",
    "                else:    \n",
    "                    plan.append(feature_plan)\n",
    "                    count+=1\n",
    "                    #find <a element where <href is present\n",
    "                    link=announcement.find('a', href=True)\n",
    "                    #check to solve the problem where the <href didn't have the complete link\n",
    "                    if ('https://' in link['href'])==True:\n",
    "                        ann=requests.get(link['href'])\n",
    "                    else:\n",
    "                        ann=requests.get('https://www.immobiliare.it'+link['href'])\n",
    "                    data1 = ann.text\n",
    "                    #create another bs4 element to access in the specific link and take commplete text from announcement\n",
    "                    soup1 = BeautifulSoup(data1,'html.parser')\n",
    "                    #access to link and take complete text\n",
    "                    a=soup1.find('div', attrs={'role':'contentinfo'}).text.strip()\n",
    "                    desc.append(a)\n",
    "        \n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we store the data in a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prezzo</th>\n",
       "      <th>Camere</th>\n",
       "      <th>Superficie</th>\n",
       "      <th>Bagni</th>\n",
       "      <th>Piano</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annuncio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>announcement_1</th>\n",
       "      <td>225000</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_2</th>\n",
       "      <td>459000</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_3</th>\n",
       "      <td>850000</td>\n",
       "      <td>5</td>\n",
       "      <td>175</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_4</th>\n",
       "      <td>1100000</td>\n",
       "      <td>5</td>\n",
       "      <td>225</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_5</th>\n",
       "      <td>149000</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_6</th>\n",
       "      <td>1300000</td>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_7</th>\n",
       "      <td>115000</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_8</th>\n",
       "      <td>695000</td>\n",
       "      <td>5</td>\n",
       "      <td>250</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_9</th>\n",
       "      <td>1220000</td>\n",
       "      <td>5</td>\n",
       "      <td>245</td>\n",
       "      <td>2</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_10</th>\n",
       "      <td>1380000</td>\n",
       "      <td>5</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Prezzo Camere Superficie Bagni Piano\n",
       "Annuncio                                              \n",
       "announcement_1    225000      2        50     1      1\n",
       "announcement_2    459000      2        85     1      A\n",
       "announcement_3    850000      5       175     2      A\n",
       "announcement_4   1100000      5       225     3      3\n",
       "announcement_5    149000      3        75     1      1\n",
       "announcement_6   1300000      4       115     2      9\n",
       "announcement_7    115000      2        58     1      3\n",
       "announcement_8    695000      5       250     3      3\n",
       "announcement_9   1220000      5       245     2      T\n",
       "announcement_10  1380000      5       140     2      2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table=pd.DataFrame({'Annuncio':title,\n",
    "                    'Prezzo':price,\n",
    "                    'Camere':n_room,\n",
    "                    'Superficie':mq,\n",
    "                    'Bagni':n_bathroom,\n",
    "                    'Piano':plan})\n",
    "#used to remove a \\n inside \"Piano\" coloumn\n",
    "table =table.set_index('Annuncio')\n",
    "table=table.replace({r'\\n': '','\\+' : ''}, regex=True)\n",
    "table.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take all the announcement from page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Annuncio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gregorio VII / San Pietro a 200 mt da Piazza S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Camilluccia - Nelle immediate vicinanze di Via...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Roma - zona Tor Pignattara - via Amedeo Cencel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TORRE SPACCATA/TORRE MAURA A pochi passi dalla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Monteverde Vecchio e più precisamente in via V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CASSIA VILLA SAN PIETRO VIA VIBIO MARIANO TRIP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Quartiere Centocelle a pochi passi dalla moder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rif: strindberg219 - RINNOVAMENTO - 75 MQ - TE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NUOVO SALARIO- VIA FOSDINOVO PIAZZA MINUCCIANO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Annuncio\n",
       "0  Gregorio VII / San Pietro a 200 mt da Piazza S...\n",
       "1  Camilluccia - Nelle immediate vicinanze di Via...\n",
       "2  Roma - zona Tor Pignattara - via Amedeo Cencel...\n",
       "3  TORRE SPACCATA/TORRE MAURA A pochi passi dalla...\n",
       "4  Monteverde Vecchio e più precisamente in via V...\n",
       "5  CASSIA VILLA SAN PIETRO VIA VIBIO MARIANO TRIP...\n",
       "6  Quartiere Centocelle a pochi passi dalla moder...\n",
       "7  Rif: strindberg219 - RINNOVAMENTO - 75 MQ - TE...\n",
       "8  NUOVO SALARIO- VIA FOSDINOVO PIAZZA MINUCCIANO..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only see if the dataframe is the data are correct, then i remove this\n",
    "annuncio=pd.DataFrame({'Annuncio':desc})\n",
    "annuncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to preprocess all text in the announcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    # removing '\\n'\n",
    "    text = text.replace('\\\\n', ' ')\n",
    "    # removing punctuation\n",
    "    tokenizer = regexp_tokenize(text, \"[\\w\\$]+\")\n",
    "    # filter the non stopwords\n",
    "    filtered = [w for w in tokenizer if not w in stopwords.words('italian')]\n",
    "    ps = PorterStemmer()\n",
    "    # removing the stem\n",
    "    filtered = [ps.stem(word) for word in filtered]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre process all the announcement and put in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_list=[]\n",
    "for i in desc:\n",
    "    processed_list.append(preprocess(i))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have a list of word processed, now i convert it to a list of string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=[' '.join(i) for i in processed_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ren=[int(i) for i in range(1,len(b)+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N.B.need to find how to increse the docId in relation of document!!!!!!!!!\n",
    "#creating dataframe with wordId and all text from the announcement processed\n",
    "df1 = pd.DataFrame({'wordId': ren, \n",
    "               'parole': b})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have used pandas and numpy to compute Tf-IDF in all dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>word_3</th>\n",
       "      <th>word_4</th>\n",
       "      <th>word_5</th>\n",
       "      <th>word_6</th>\n",
       "      <th>word_7</th>\n",
       "      <th>word_8</th>\n",
       "      <th>word_9</th>\n",
       "      <th>word_10</th>\n",
       "      <th>...</th>\n",
       "      <th>word_3453</th>\n",
       "      <th>word_3454</th>\n",
       "      <th>word_3455</th>\n",
       "      <th>word_3456</th>\n",
       "      <th>word_3457</th>\n",
       "      <th>word_3458</th>\n",
       "      <th>word_3459</th>\n",
       "      <th>word_3460</th>\n",
       "      <th>word_3461</th>\n",
       "      <th>word_3462</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annuncio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>announcement_1</th>\n",
       "      <td>0.020719</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>0.009169</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>0.004999</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>announcement_10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 3462 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   word_1    word_2    word_3    word_4    word_5    word_6  \\\n",
       "Annuncio                                                                      \n",
       "announcement_1   0.020719  0.008362  0.009169  0.004999  0.004999  0.004999   \n",
       "announcement_2   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "announcement_3   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "announcement_4   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "announcement_5   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "announcement_6   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "announcement_7   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "announcement_8   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "announcement_9   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "announcement_10  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "                   word_7    word_8    word_9   word_10    ...      word_3453  \\\n",
       "Annuncio                                                   ...                  \n",
       "announcement_1   0.004999  0.001565  0.000866  0.000935    ...            0.0   \n",
       "announcement_2   0.000000  0.000000  0.000000  0.000000    ...            0.0   \n",
       "announcement_3   0.000000  0.000000  0.000000  0.000000    ...            0.0   \n",
       "announcement_4   0.000000  0.000000  0.000000  0.000000    ...            0.0   \n",
       "announcement_5   0.000000  0.000000  0.000000  0.000000    ...            0.0   \n",
       "announcement_6   0.000000  0.000000  0.000000  0.000000    ...            0.0   \n",
       "announcement_7   0.000000  0.000000  0.000000  0.000000    ...            0.0   \n",
       "announcement_8   0.000000  0.000000  0.000000  0.000000    ...            0.0   \n",
       "announcement_9   0.000000  0.000000  0.000000  0.000000    ...            0.0   \n",
       "announcement_10  0.000000  0.000000  0.000456  0.000000    ...            0.0   \n",
       "\n",
       "                 word_3454  word_3455  word_3456  word_3457  word_3458  \\\n",
       "Annuncio                                                                 \n",
       "announcement_1         0.0        0.0        0.0        0.0        0.0   \n",
       "announcement_2         0.0        0.0        0.0        0.0        0.0   \n",
       "announcement_3         0.0        0.0        0.0        0.0        0.0   \n",
       "announcement_4         0.0        0.0        0.0        0.0        0.0   \n",
       "announcement_5         0.0        0.0        0.0        0.0        0.0   \n",
       "announcement_6         0.0        0.0        0.0        0.0        0.0   \n",
       "announcement_7         0.0        0.0        0.0        0.0        0.0   \n",
       "announcement_8         0.0        0.0        0.0        0.0        0.0   \n",
       "announcement_9         0.0        0.0        0.0        0.0        0.0   \n",
       "announcement_10        0.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "                 word_3459  word_3460  word_3461  word_3462  \n",
       "Annuncio                                                     \n",
       "announcement_1         0.0        0.0        0.0        0.0  \n",
       "announcement_2         0.0        0.0        0.0        0.0  \n",
       "announcement_3         0.0        0.0        0.0        0.0  \n",
       "announcement_4         0.0        0.0        0.0        0.0  \n",
       "announcement_5         0.0        0.0        0.0        0.0  \n",
       "announcement_6         0.0        0.0        0.0        0.0  \n",
       "announcement_7         0.0        0.0        0.0        0.0  \n",
       "announcement_8         0.0        0.0        0.0        0.0  \n",
       "announcement_9         0.0        0.0        0.0        0.0  \n",
       "announcement_10        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[10 rows x 3462 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize and generate count vectors\n",
    "word_vec = df1.parole.apply(str.split).apply(pd.value_counts).fillna(0)\n",
    "# Compute term frequencies\n",
    "tf = word_vec.divide(np.sum(word_vec, axis=1), axis=0)\n",
    "# Compute inverse document frequencies\n",
    "idf = np.log10(len(tf) / word_vec[word_vec > 0].count())\n",
    "# Compute TF-IDF vectors\n",
    "tfidf = np.multiply(tf, idf.to_frame().T)\n",
    "#L2 (Euclidean) normalization\n",
    "l2_norm = np.sum(np.sqrt(tfidf), axis=1)\n",
    "#Normalized TF-IDF vectors\n",
    "tfidf_norm = (tfidf.T / l2_norm).T\n",
    "#put in a dataframe\n",
    "second_mat=pd.DataFrame(tfidf_norm)\n",
    "word_column=['word_'+str(i) for i in range(1,len(second_mat.columns)+1) ]\n",
    "second_mat.columns=word_column\n",
    "second_mat=second_mat.set_index(table.index)\n",
    "second_mat.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_mat.to_csv(r'C:\\Users\\Daniele\\Desktop\\Matrix_TfIdf.csv')\n",
    "table.to_csv(r'C:\\Users\\Daniele\\Desktop\\Matrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'R'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-aed646c3b522>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Using sklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mkm\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k-means++'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mkm1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k-means++'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_array1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# Get cluster assignment labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    885\u001b[0m         \"\"\"\n\u001b[0;32m    886\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 887\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36m_check_fit_data\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    856\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_fit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[1;34m\"\"\"Verify that the number of samples given is larger than k\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 858\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             raise ValueError(\"n_samples=%d should be >= n_clusters=%d\" % (\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    431\u001b[0m                                       force_all_finite)\n\u001b[0;32m    432\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'R'"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame to matrix\n",
    "dataset_array =second_mat.values\n",
    "dataset_array1=table.values\n",
    "# Using sklearn\n",
    "km =KMeans(n_clusters=5, init='k-means++', tol=0.0001).fit(dataset_array)\n",
    "km1=KMeans(n_clusters=5, init='k-means++', tol=0.0001).fit(dataset_array1)\n",
    "# Get cluster assignment labels\n",
    "labels = km.labels_\n",
    "labels1 = km1.labels_\n",
    "#put the result of cluster in a dataframe\n",
    "results = pd.DataFrame([second_mat.index,labels]).T\n",
    "results1 = pd.DataFrame([table.index,labels]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1_x</th>\n",
       "      <th>1_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>announcement_1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>announcement_2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>announcement_3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>announcement_4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>announcement_5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>announcement_6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>announcement_7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>announcement_8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>announcement_9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>announcement_10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>announcement_11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>announcement_12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>announcement_13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>announcement_14</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>announcement_15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>announcement_16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>announcement_17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>announcement_18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0 1_x 1_y\n",
       "0    announcement_1   1   1\n",
       "1    announcement_2   1   1\n",
       "2    announcement_3   1   1\n",
       "3    announcement_4   2   2\n",
       "4    announcement_5   1   1\n",
       "5    announcement_6   0   0\n",
       "6    announcement_7   1   1\n",
       "7    announcement_8   0   0\n",
       "8    announcement_9   1   1\n",
       "9   announcement_10   1   1\n",
       "10  announcement_11   1   1\n",
       "11  announcement_12   0   0\n",
       "12  announcement_13   1   1\n",
       "13  announcement_14   4   4\n",
       "14  announcement_15   1   1\n",
       "15  announcement_16   1   1\n",
       "16  announcement_17   1   1\n",
       "17  announcement_18   3   3"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result=pd.merge(results, results1, on=0)\n",
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection / union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16129032258064516"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_similarity(labels,labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
